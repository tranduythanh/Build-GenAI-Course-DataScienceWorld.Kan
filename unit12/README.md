# GraphRAG Application with Nodes Integration

Má»™t á»©ng dá»¥ng GraphRAG hoÃ n chá»‰nh sá»­ dá»¥ng LlamaIndex, Neo4j vÃ  Streamlit Ä‘á»ƒ xÃ¢y dá»±ng vÃ  truy váº¥n knowledge graph tá»« cÃ¡c tÃ i liá»‡u HTML/Markdown, **bao gá»“m cáº£ nodes (chunks) gá»‘c**.

## ğŸ—ï¸ Kiáº¿n trÃºc

á»¨ng dá»¥ng Ä‘Æ°á»£c chia thÃ nh 2 pháº§n chÃ­nh:

1. **`build_index.py`** - Script xÃ¢y dá»±ng index (cháº¡y trong terminal)
2. **`app.py`** - Giao diá»‡n Streamlit Ä‘á»ƒ truy váº¥n (cháº¡y trong browser)

### ğŸ†• TÃ­nh nÄƒng má»›i: Nodes Integration
- **LÆ°u trá»¯ nodes gá»‘c**: CÃ¡c text chunks ban Ä‘áº§u Ä‘Æ°á»£c lÆ°u vÃ o `index_data/nodes.pkl`
- **Sá»­ dá»¥ng trong query**: Query engine cÃ³ thá»ƒ truy cáº­p cáº£ graph structure vÃ  text chunks gá»‘c
- **TÄƒng Ä‘á»™ chÃ­nh xÃ¡c**: Káº¿t há»£p thÃ´ng tin tá»« entities, communities vÃ  chunks thÃ´

## ğŸ“‹ YÃªu cáº§u há»‡ thá»‘ng

### Dependencies
```bash
# CÃ i Ä‘áº·t tá»« requirements.txt
pip install -r requirements.txt

# Hoáº·c sá»­ dá»¥ng Makefile
make install
```

**CÃ¡c package chÃ­nh:**
xem trong file requirements.txt

### Neo4j Database
Sá»­ dá»¥ng Docker Compose vá»›i Neo4j 5.15 Community Edition:
```bash
make neo4j-start    # Khá»Ÿi Ä‘á»™ng Neo4j
make neo4j-status   # Kiá»ƒm tra tráº¡ng thÃ¡i
make neo4j-stop     # Dá»«ng Neo4j
make neo4j-reset    # Reset database
```

### Cáº¥u hÃ¬nh Environment Variables
Táº¡o file `.env` hoáº·c export cÃ¡c biáº¿n mÃ´i trÆ°á»ng:

```bash
# Required
export OPENAI_API_KEY="your_openai_api_key"

# Optional (cÃ³ default values)
export NEO4J_URI="bolt://localhost:7687"
export NEO4J_USERNAME="neo4j"
export NEO4J_PASSWORD="password"

# Build configuration
export NUM_MARKDOWN_FILES="50"
export CHUNK_SIZE="2048"
export CHUNK_OVERLAP="200"
export MAX_PATHS_PER_CHUNK="10"
export SIMILARITY_TOP_K="10"
```

## ğŸš€ Quick Start

1. **Chuáº©n bá»‹ dá»¯ liá»‡u**
```bash
# Äáº·t files vÃ o thÆ° má»¥c data/
mkdir -p data
# Copy your .html hoáº·c .md files vÃ o data/
# CÃ¡c file html/md trong thÆ° má»¥c data/ sáº½ Ä‘Æ°á»£c chuyá»ƒn thÃ nh markdown vÃ  Ä‘Æ°á»£c xá»­ lÃ½ Ä‘á»ƒ táº¡o ra cÃ¡c text chunks
```

2. **Khá»Ÿi Ä‘á»™ng Neo4j**
```bash
make neo4j-start
make test-connection
```

3. **Build index**
```bash
make build-index
```

4. **Cháº¡y Streamlit app**
```bash
make run
```

## ğŸ”„ Quy trÃ¬nh Build Index Chi tiáº¿t

```mermaid
graph TD
    A[ğŸ“ HTML/MD Files] --> B[ğŸ”„ HTML to Markdown]
    B --> C[ğŸ“– Load Documents]
    C --> D[ğŸ¤– Setup LLM: GPT-4o-mini]
    D --> E[ğŸ§  Setup Embedding: BGE-small]
    E --> F[âœ‚ï¸ Create Text Chunks]
    F --> G[ğŸ•¸ï¸ Setup KG Extractor]
    G --> H[ğŸ—„ï¸ Setup Neo4j Store]
    H --> I[ğŸ” Extract Knowledge]
    I --> J[ğŸ’¾ Store Triplets]
    J --> K[ğŸ˜ï¸ Build Communities]
    K --> L[ğŸ”§ Setup Query Engine]
    L --> M[ğŸ’¿ Save Index Metadata]
    M --> N[ğŸ’¾ Save Nodes to Disk]
    N --> O[âœ… Ready for Queries]

    subgraph "Nodes Processing"
        F --> F1[Chunk Size: 2048 tokens]
        F --> F2[Overlap: 200 tokens]
        F --> F3[Save as nodes.pkl]
        N --> N1[Store text + metadata]
        N --> N2[Enable chunk retrieval]
    end

    subgraph "Knowledge Extraction"
        I --> I1[Extract Entities]
        I --> I2[Extract Relations]
        I --> I3[Max 10 paths/chunk]
    end
```

### ğŸ”§ Cáº¥u hÃ¬nh tá»‘i Æ°u:
- **Chunk Size**: 2048 tokens (tá»‘i Æ°u cho GPT-4o-mini vá»›i 128K context)
- **Max Paths**: 10 per chunk (tÄƒng tá»« 2 Ä‘á»ƒ extract Ä‘áº§y Ä‘á»§ hÆ¡n)
- **Similarity Top K**: 10 (balance giá»¯a cháº¥t lÆ°á»£ng vÃ  performance)
- **Files Processed**: 50 (tÄƒng tá»« 10 Ä‘á»ƒ cÃ³ dataset lá»›n hÆ¡n)

## ğŸ” Quy trÃ¬nh Query vá»›i Nodes Integration

```mermaid
graph TD
    A[ğŸ¯ User Query] --> B[ğŸ§  GraphRAG Query Engine]
    B --> C[ğŸ“‹ Extract Entities]
    C --> D[ğŸ˜ï¸ Get Communities]
    D --> E[ğŸ“„ Get Relevant Chunks]
    E --> F[ğŸ”º Get Related Triplets]
    F --> G[ğŸ¤– LLM Synthesis]
    G --> H[âœ¨ Final Response]

    subgraph "Entity Extraction"
        C --> C1[Embedding similarity search]
        C --> C2[Find top K entities]
        C --> C3[Pattern matching in graph]
    end

    subgraph "Community Retrieval"
        D --> D1[Get entity communities]
        D --> D2[Load cached summaries]
        D --> D3[Rank by relevance]
    end

    subgraph "Chunk Retrieval (NEW!)"
        E --> E1[Search in saved nodes]
        E --> E2[Keyword matching]
        E --> E3[Entity co-occurrence]
        E --> E4[Score and rank top 3]
    end

    subgraph "LLM Synthesis"
        G --> G1[Batch processing]
        G --> G2[Combine communities + chunks]
        G --> G3[Generate coherent answer]
    end

    style E fill:#e1f5fe
    style G fill:#fff3e0
```

### ğŸ¯ Æ¯u Ä‘iá»ƒm cá»§a implementation hiá»‡n táº¡i:

- **Batch Processing**: Gom nhiá»u communities thÃ nh 1 LLM call Ä‘á»ƒ tÄƒng hiá»‡u quáº£
- **Caching**: Communities Ä‘Æ°á»£c cache trong file `community/summary.json`
- **Performance Optimization**: Giá»›i háº¡n top 10 communities vÃ  top 3 chunks
- **Debug-friendly**: Hiá»ƒn thá»‹ source nodes vÃ  processing steps trong UI

## ğŸ§  Vai trÃ² cá»§a EMBEDDING_MODEL

### Model: BAAI/bge-small-en-v1.5

**Embedding Model** Ä‘Ã³ng vai trÃ² quan trá»ng trong há»‡ thá»‘ng GraphRAG:

#### ğŸ¯ Chá»©c nÄƒng chÃ­nh:
1. **Vector Representation**: Chuyá»ƒn Ä‘á»•i text chunks thÃ nh 768-dimensional vectors
2. **Similarity Search**: TÃ¬m kiáº¿m entities vÃ  chunks tÆ°Æ¡ng tá»± vá»›i query
3. **Retrieval**: Láº¥y context liÃªn quan cho cÃ¢u tráº£ lá»i

#### ğŸ” Quy trÃ¬nh hoáº¡t Ä‘á»™ng:
```mermaid
graph LR
    A[Text Chunk] --> B[BGE Embedding Model]
    B --> C[768-dim Vector]
    C --> D[Index Retriever]
    D --> E[Similarity Search]
    E --> F[Relevant Context]
    F --> G[LLM Answer]
```

#### âš¡ Táº¡i sao chá»n BGE-small-en-v1.5:
- **Hiá»‡u suáº¥t cao**: Top performance trÃªn MTEB benchmark
- **KÃ­ch thÆ°á»›c nhá»**: ~133MB, phÃ¹ há»£p cho local deployment
- **Semantic Understanding**: Hiá»ƒu ngá»¯ nghÄ©a tá»‘t cho entity extraction
- **Open source**: Miá»…n phÃ­, khÃ´ng cáº§n API key

## ğŸ’¬ Example Queries

Sau khi build index thÃ nh cÃ´ng, báº¡n cÃ³ thá»ƒ thá»­ cÃ¡c cÃ¢u há»i máº«u sau trong Streamlit app:

### ğŸ¯ Recommended Queries:

1. **"What are the main components of LLM-powered autonomous agents?"**
   - TÃ¬m hiá»ƒu vá» cÃ¡c thÃ nh pháº§n chÃ­nh cá»§a LLM agents
   - Káº¿t quáº£: Planning, Memory, Tool use, Action

2. **"How does planning work in LLM agents?"**
   - KhÃ¡m phÃ¡ cÆ¡ cháº¿ planning trong LLM agents
   - Káº¿t quáº£: Task decomposition, subgoal generation, reflection

3. **"What are the different types of memory in agent systems?"**
   - TÃ¬m hiá»ƒu vá» cÃ¡c loáº¡i memory trong há»‡ thá»‘ng agent
   - Káº¿t quáº£: Sensory memory, short-term memory, long-term memory

### ğŸ’¡ Tips for Better Queries:
- Sá»­ dá»¥ng cÃ¢u há»i cá»¥ thá»ƒ vÃ  rÃµ rÃ ng
- Táº­p trung vÃ o cÃ¡c khÃ¡i niá»‡m chÃ­nh trong tÃ i liá»‡u
- CÃ³ thá»ƒ há»i vá» relationships giá»¯a cÃ¡c concepts
- Thá»­ cÃ¡c cÃ¢u há»i "How", "What", "Why" Ä‘á»ƒ cÃ³ cÃ¢u tráº£ lá»i chi tiáº¿t

## ğŸ“Š Giao diá»‡n Streamlit

### ğŸ” Query Interface Tab
- **Real-time Processing**: Hiá»ƒn thá»‹ step-by-step progress
- **Chat History**: LÆ°u trá»¯ vÃ  hiá»ƒn thá»‹ lá»‹ch sá»­ há»i Ä‘Ã¡p
- **Debug Information**: 
  - Source nodes used trong query
  - **Relevant text chunks** tá»« saved nodes
  - Related triplets tá»« knowledge graph
  - Community information
  - Query processing details

### ğŸ“Š Graph Analysis Tab
- **Interactive Triplets Graph**: Visualization vá»›i Plotly vÃ  NetworkX
- **Communities Graph**: Community structure visualization
- **Statistics Dashboard**: Metrics vá» entities, relations, communities
- **Data Table**: Browse táº¥t cáº£ triplets vá»›i search functionality
- **Community Details**: Xem summaries cá»§a tá»«ng community

### Sidebar Information:
- **Index Metadata**: Timestamp, files processed, index type
- **Community Status**: Cache status vÃ  sá»‘ lÆ°á»£ng communities
- **Navigation Menu**: Chuyá»ƒn Ä‘á»•i giá»¯a cÃ¡c functions

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c

```
project/
â”œâ”€â”€ Core Application Files
â”‚   â”œâ”€â”€ app.py                         # Streamlit query interface (451 lines)
â”‚   â”œâ”€â”€ build_index.py                 # Index building script (259 lines)
â”‚   â”œâ”€â”€ const.py                       # Configuration constants (77 lines)
â”‚   â””â”€â”€ requirements.txt               # Python dependencies (28 packages)
â”‚
â”œâ”€â”€ Core Logic Modules
â”‚   â”œâ”€â”€ graph_rag_query_engine.py      # Custom query engine (680 lines)
â”‚   â”œâ”€â”€ graph_rag_store.py             # Neo4j graph store (350 lines)
â”‚   â”œâ”€â”€ graph_rag_extractor.py         # Knowledge extractor (307 lines)
â”‚   â”œâ”€â”€ utils.py                       # Shared utilities (403 lines)
â”‚   â””â”€â”€ build_utils.py                 # Build-specific utilities (367 lines)
â”‚
â”œâ”€â”€ Data Processing
â”‚   â”œâ”€â”€ html_to_md_converter.py        # HTMLâ†’Markdown converter (197 lines)
â”‚   â”œâ”€â”€ data/                          # Input documents (HTML/MD)
â”‚   â””â”€â”€ index_data/                    # Generated index data
â”‚       â”œâ”€â”€ index_metadata.pkl         # Build metadata
â”‚       â”œâ”€â”€ files_df.pkl              # Files dataframe
â”‚       â””â”€â”€ nodes.pkl                 # ğŸ†• Original text chunks
â”‚
â”œâ”€â”€ Infrastructure
â”‚   â”œâ”€â”€ docker-compose.yml             # Neo4j setup (Neo4j 5.15)
â”‚   â”œâ”€â”€ setup_neo4j.sh                 # Neo4j management script
â”‚   â”œâ”€â”€ Makefile                       # Task automation (65 lines)
â”‚   â””â”€â”€ .streamlit/                    # Streamlit configuration
â”‚
â”œâ”€â”€ Community Data
â”‚   â””â”€â”€ community/                     # Community summaries cache
â”‚       â””â”€â”€ summary.json              # Cached community data
â”‚
â””â”€â”€ Testing
    â””â”€â”€ tests/                         # Unit tests
        â”œâ”€â”€ test_config.py             # Configuration tests
        â”œâ”€â”€ test_neo4j_connection.py   # Neo4j connection tests
        â””â”€â”€ test_nodes_integration.py  # ğŸ†• Nodes integration tests
```


## ğŸ”§ Technical Implementation Details

### GraphRAGQueryEngine Features:
- **Batch Processing**: Gom nhiá»u communities thÃ nh 1 LLM call
- **Smart Limiting**: Top 10 communities + top 3 chunks Ä‘á»ƒ optimize performance
- **Entity Extraction**: Sá»­ dá»¥ng embedding similarity vÃ  regex pattern matching
- **Chunk Integration**: Káº¿t há»£p graph data vá»›i original text chunks
- **Debug Information**: Comprehensive logging vÃ  debug output

### Graph Store Features:
- **Community Caching**: Tá»± Ä‘á»™ng cache communities trong `community/summary.json`
- **Lazy Loading**: Load communities tá»« cache khi cáº§n
- **Session State**: Cache graph store instance trong Streamlit session
- **Error Handling**: Graceful fallback khi cache corrupted

### Build Process Optimizations:
- **Increased Chunk Size**: 2048 tokens (tá»« 500) Ä‘á»ƒ táº­n dá»¥ng GPT-4o-mini
- **More Extraction Paths**: 10 paths per chunk (tá»« 2) Ä‘á»ƒ extract Ä‘áº§y Ä‘á»§ hÆ¡n
- **No Node Limit**: Process táº¥t cáº£ nodes thay vÃ¬ giá»›i háº¡n
- **Better Error Handling**: Continue on warnings, fail only on critical errors
