# GraphRAG Application

Má»™t á»©ng dá»¥ng GraphRAG hoÃ n chá»‰nh sá»­ dá»¥ng LlamaIndex, Neo4j vÃ  Streamlit Ä‘á»ƒ xÃ¢y dá»±ng vÃ  truy váº¥n knowledge graph tá»« cÃ¡c tÃ i liá»‡u markdown.

## ğŸ—ï¸ Kiáº¿n trÃºc

á»¨ng dá»¥ng Ä‘Æ°á»£c chia thÃ nh 2 pháº§n chÃ­nh:

1. **`build_index.py`** - Script xÃ¢y dá»±ng index (cháº¡y trong terminal)
2. **`app.py`** - Giao diá»‡n Streamlit Ä‘á»ƒ truy váº¥n (cháº¡y trong browser)

## ğŸ“‹ YÃªu cáº§u há»‡ thá»‘ng

### Dependencies
```bash
pip install streamlit llama-index neo4j openai pandas beautifulsoup4 markdownify huggingface-hub
```

### Neo4j Database
- Neo4j Community Edition hoáº·c Neo4j AuraDB
- Cáº¥u hÃ¬nh connection trong `const.py`

### OpenAI API Key
- Cáº§n cÃ³ OpenAI API key Ä‘á»ƒ sá»­ dá»¥ng GPT models
- Cáº¥u hÃ¬nh trong `const.py`

## ğŸš€ HÆ°á»›ng dáº«n sá»­ dá»¥ng

### BÆ°á»›c 1: Chuáº©n bá»‹ dá»¯ liá»‡u

Äáº·t cÃ¡c file HTML hoáº·c Markdown vÃ o thÆ° má»¥c `data/`:

```
data/
â”œâ”€â”€ document1.html
â”œâ”€â”€ document2.md
â”œâ”€â”€ article.html
â””â”€â”€ notes.md
```

### BÆ°á»›c 2: Cáº¥u hÃ¬nh

Cáº­p nháº­t file `const.py` vá»›i thÃ´ng tin cá»§a báº¡n:

```python
# Neo4j Configuration
NEO4J_URI = "bolt://localhost:7687"
NEO4J_USERNAME = "neo4j"
NEO4J_PASSWORD = "your_password"

# OpenAI Configuration
OPENAI_API_KEY = "your_openai_api_key"
```

### BÆ°á»›c 3: XÃ¢y dá»±ng Index

Cháº¡y script build index trong terminal:

```bash
python build_index.py
```

## ğŸ”„ Quy trÃ¬nh Build Index Chi tiáº¿t

```mermaid
graph TD
    A[ğŸ“ Input: HTML/MD Files] --> B[ğŸ”„ HTML to Markdown Conversion]
    B --> C[ğŸ“– Load Documents]
    C --> D[ğŸ¤– Setup LLM: GPT-4o-mini]
    D --> E[ğŸ§  Setup Embedding Model: BGE-small]
    E --> F[âœ‚ï¸ Create Text Chunks]
    F --> G[ğŸ•¸ï¸ Setup KG Extractor]
    G --> H[ğŸ—„ï¸ Setup Neo4j Graph Store]
    H --> I[ğŸ” Extract Knowledge from Chunks]
    I --> J[ğŸ’¾ Store Triplets in Neo4j]
    J --> K[ğŸ˜ï¸ Build Communities]
    K --> L[ğŸ”§ Setup Query Engine]
    L --> M[ğŸ’¿ Save Index Metadata]
    M --> N[âœ… Ready for Queries]

    subgraph "Chunk Processing"
        F --> F1[Chunk Size: 500 tokens]
        F --> F2[Overlap: 20 tokens]
        F --> F3[Can be optimized for GPT-4o-mini]
    end

    subgraph "Knowledge Extraction"
        I --> I1[Extract Entities]
        I --> I2[Extract Relations]
        I --> I3[Max 2 paths/chunk]
    end

    subgraph "Embedding Process"
        E --> E1[BGE-small-en-v1.5]
        E --> E2[Vector Embeddings]
        E --> E3[Similarity Search]
    end
```

### CÃ¡c bÆ°á»›c chi tiáº¿t:

1. **ğŸ”„ HTML to Markdown Conversion** (`convert_html_to_markdown`)
   - Chuyá»ƒn Ä‘á»•i file HTML thÃ nh Markdown
   - Sá»­ dá»¥ng BeautifulSoup vÃ  markdownify
   - Skip files Ä‘Ã£ Ä‘Æ°á»£c convert vÃ  up-to-date

2. **ğŸ“– Load Documents** (`load_data`)
   - Táº£i tá»‘i Ä‘a 50 file markdown (cÃ³ thá»ƒ cáº¥u hÃ¬nh)
   - Táº¡o Document objects vá»›i metadata
   - Xá»­ lÃ½ encoding UTF-8

3. **ğŸ¤– Setup LLM** (`setup_llm`)
   - Model: **GPT-4o-mini** (128K context window)
   - Tá»‘i Æ°u cho cost vÃ  performance
   - Xá»­ lÃ½ knowledge extraction

4. **ğŸ§  Setup Embedding Model** (`setup_embedding_model`)
   - Model: **BAAI/bge-small-en-v1.5**
   - Vai trÃ²: Táº¡o vector embeddings cho text chunks
   - Má»¥c Ä‘Ã­ch: Similarity search vÃ  retrieval

5. **âœ‚ï¸ Create Text Chunks** (`create_nodes`)
   - Chunk size: **500 tokens** (cÃ³ thá»ƒ tá»‘i Æ°u thÃªm cho GPT-4o-mini)
   - Overlap: **20 tokens** (Ä‘áº£m báº£o context liÃªn tá»¥c)
   - Sá»­ dá»¥ng SentenceSplitter

6. **ğŸ•¸ï¸ Setup KG Extractor** (`setup_kg_extractor`)
   - Custom GraphRAGExtractor vá»›i CSV format
   - Fallback: SimpleLLMPathExtractor
   - Max 2 paths per chunk

7. **ğŸ—„ï¸ Setup Neo4j Graph Store** (`setup_graph_store`)
   - Káº¿t ná»‘i Neo4j database
   - Clear existing data
   - Chuáº©n bá»‹ cho viá»‡c lÆ°u trá»¯ graph

8. **ğŸ” Extract Knowledge** (`build_index`)
   - Xá»­ lÃ½ **Táº¤T Cáº¢** chunks (khÃ´ng giá»›i háº¡n)
   - Extract entities vÃ  relationships
   - Detailed logging vá»›i mÃ u sáº¯c

9. **ğŸ’¾ Store in Neo4j**
   - LÆ°u entities vÃ  relationships
   - Format: (Entity)-[RELATION]->(Entity)
   - Cypher queries Ä‘á»ƒ insert data

10. **ğŸ˜ï¸ Build Communities** (`build_communities`)
    - PhÃ¢n tÃ­ch cáº¥u trÃºc community
    - Táº¡o summaries (náº¿u há»— trá»£)

## ğŸ§  Vai trÃ² cá»§a EMBEDDING_MODEL

### Model: BAAI/bge-small-en-v1.5

**Embedding Model** Ä‘Ã³ng vai trÃ² quan trá»ng trong há»‡ thá»‘ng GraphRAG:

#### ğŸ¯ Chá»©c nÄƒng chÃ­nh:
1. **Vector Representation**: Chuyá»ƒn Ä‘á»•i text chunks thÃ nh vector embeddings
2. **Similarity Search**: TÃ¬m kiáº¿m chunks tÆ°Æ¡ng tá»± dá»±a trÃªn semantic similarity
3. **Retrieval**: Láº¥y context liÃªn quan cho cÃ¢u tráº£ lá»i

#### ğŸ” Quy trÃ¬nh hoáº¡t Ä‘á»™ng:
```mermaid
graph LR
    A[Text Chunk] --> B[BGE Embedding Model]
    B --> C[768-dim Vector]
    C --> D[Vector Store]
    D --> E[Similarity Search]
    E --> F[Relevant Context]
    F --> G[LLM Answer]
```

#### âš¡ Táº¡i sao chá»n BGE-small-en-v1.5:
- **Hiá»‡u suáº¥t cao**: Top performance trÃªn MTEB benchmark
- **KÃ­ch thÆ°á»›c nhá»**: ~133MB, phÃ¹ há»£p cho local deployment
- **Äa ngÃ´n ngá»¯**: Há»— trá»£ tiáº¿ng Anh tá»‘t
- **Open source**: Miá»…n phÃ­, khÃ´ng cáº§n API key

#### ğŸ”§ Cáº¥u hÃ¬nh trong code:
```python
# const.py
EMBEDDING_MODEL = "BAAI/bge-small-en-v1.5"

# build_utils.py
embed_model = HuggingFaceEmbedding(model_name=EMBEDDING_MODEL)
```

### BÆ°á»›c 4: Cháº¡y á»©ng dá»¥ng Streamlit

Sau khi build index thÃ nh cÃ´ng, cháº¡y á»©ng dá»¥ng Streamlit:

```bash
streamlit run app.py
```

á»¨ng dá»¥ng sáº½ má»Ÿ táº¡i `http://localhost:8501`

## ğŸ›ï¸ Cáº¥u hÃ¬nh tá»‘i Æ°u (ÄÃ£ cáº­p nháº­t)

### Environment Variables

```bash
# Sá»‘ lÆ°á»£ng file markdown Ä‘á»ƒ xá»­ lÃ½ (máº·c Ä‘á»‹nh: 50)
export NUM_MARKDOWN_FILES=50

# Xá»­ lÃ½ Táº¤T Cáº¢ nodes (khÃ´ng giá»›i háº¡n)
# NUM_NODES_TO_PROCESS khÃ´ng cÃ²n Ä‘Æ°á»£c sá»­ dá»¥ng

# KÃ­ch thÆ°á»›c chunk (cÃ³ thá»ƒ tá»‘i Æ°u cho GPT-4o-mini)
export CHUNK_SIZE=500

# Chunk overlap
export CHUNK_OVERLAP=20

# Max paths per chunk
export MAX_PATHS_PER_CHUNK=2

# Similarity top K
export SIMILARITY_TOP_K=10
```

### Cáº¥u hÃ¬nh máº·c Ä‘á»‹nh

GiÃ¡ trá»‹ máº·c Ä‘á»‹nh tá»« `const.py`:

- `NUM_MARKDOWN_FILES`: **50** (tÄƒng tá»« 10)
- `CHUNK_SIZE`: **500** (cÃ³ thá»ƒ tá»‘i Æ°u thÃªm cho GPT-4o-mini)
- `CHUNK_OVERLAP`: **20**
- `MAX_PATHS_PER_CHUNK`: **2**
- `SIMILARITY_TOP_K`: 10

### ğŸ’¡ Gá»£i Ã½ tá»‘i Æ°u hÃ³a:

Äá»ƒ táº­n dá»¥ng tá»‘t hÆ¡n GPT-4o-mini (128K context window), báº¡n cÃ³ thá»ƒ:

1. **TÄƒng CHUNK_SIZE** lÃªn 4096-8192 tokens Ä‘á»ƒ giáº£m API requests
2. **TÄƒng CHUNK_OVERLAP** lÃªn 100-200 tokens Ä‘á»ƒ Ä‘áº£m báº£o context liÃªn tá»¥c
3. **TÄƒng MAX_PATHS_PER_CHUNK** lÃªn 5-10 Ä‘á»ƒ trÃ­ch xuáº¥t nhiá»u relationships hÆ¡n

VÃ­ dá»¥ cáº¥u hÃ¬nh tá»‘i Æ°u:
```bash
export CHUNK_SIZE=4096
export CHUNK_OVERLAP=100
export MAX_PATHS_PER_CHUNK=5
```

## ğŸ“Š Giao diá»‡n Streamlit

### Tab 1: Query Interface
- **Quick Queries**: CÃ¡c cÃ¢u há»i máº«u vá» LLM agents
- **Custom Query**: Nháº­p cÃ¢u há»i tÃ¹y chá»‰nh
- **Real-time response**: Sá»­ dá»¥ng GraphRAG Ä‘á»ƒ tráº£ lá»i

### Tab 2: Graph Analysis
- Thá»‘ng kÃª vá» knowledge graph
- Hiá»ƒn thá»‹ sample triplets
- Community summaries (náº¿u cÃ³)
- Neo4j connection status

### Tab 3: Data Info
- ThÃ´ng tin vá» cÃ¡c file Ä‘Ã£ xá»­ lÃ½
- Metadata cá»§a index
- Build statistics

## ğŸ”§ Troubleshooting

### Lá»—i "No pre-built index found"
```bash
# Cháº¡y láº¡i build index
python build_index.py
```

### Lá»—i Neo4j connection
- Kiá»ƒm tra Neo4j service Ä‘ang cháº¡y
- Kiá»ƒm tra thÃ´ng tin káº¿t ná»‘i trong `const.py`
- Kiá»ƒm tra firewall/network

### Lá»—i OpenAI API
- Kiá»ƒm tra API key trong `const.py`
- Kiá»ƒm tra quota vÃ  billing
- Kiá»ƒm tra network connection

### Lá»—i Embedding Model
```bash
# Download model manually náº¿u cáº§n
python -c "from llama_index.embeddings.huggingface import HuggingFaceEmbedding; HuggingFaceEmbedding(model_name='BAAI/bge-small-en-v1.5')"
```

### Lá»—i "No data found in Neo4j"
- Cháº¡y láº¡i `python build_index.py`
- Kiá»ƒm tra log Ä‘á»ƒ xem cÃ³ lá»—i trong quÃ¡ trÃ¬nh build khÃ´ng

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c

```
.
â”œâ”€â”€ app.py                      # Streamlit query interface
â”œâ”€â”€ build_index.py             # Index building script (MAIN)
â”œâ”€â”€ build_utils.py             # Build-specific utilities
â”œâ”€â”€ utils.py                   # Shared utility functions
â”œâ”€â”€ const.py                   # Configuration constants
â”œâ”€â”€ graph_rag_extractor.py     # Custom KG extractor
â”œâ”€â”€ graph_rag_store.py         # Custom graph store
â”œâ”€â”€ graph_rag_query_engine.py  # Custom query engine
â”œâ”€â”€ html_to_md_converter.py    # HTML to Markdown converter
â”œâ”€â”€ data/                      # Input documents
â”‚   â”œâ”€â”€ *.html
â”‚   â””â”€â”€ *.md
â”œâ”€â”€ index_data/                # Generated index metadata
â”‚   â”œâ”€â”€ index_metadata.pkl
â”‚   â””â”€â”€ files_df.pkl
â””â”€â”€ README.md                  # This file
```

## ğŸ“ Logs vÃ  Monitoring

### Build Index Logs
Script `build_index.py` sáº½ hiá»ƒn thá»‹ progress vá»›i timestamp vÃ  mÃ u sáº¯c:
```
ğŸ•¸ï¸ GraphRAG Index Builder
==================================================

ğŸ“‹ Configuration:
  - Number of markdown files: 50
  - Number of nodes to process: ALL (no limit)
  - Chunk size: 500 (can be optimized for GPT-4o-mini)
  - Chunk overlap: 20
  - Max paths per chunk: 2
  - Similarity top K: 10
  - Model: gpt-4o-mini (128K context window)

[14:30:15] Step 1/10: Converting HTML files to Markdown...
[14:30:16] Step 2/10: Loading markdown files...
...
[14:35:20] ğŸ‰ GraphRAG Index Building Completed Successfully!

ğŸ“Š Statistics:
  - Total triplets in graph: 1,234
  - Documents processed: 45
  - Nodes created: 156
  - Nodes processed: ALL (156)
```

### Streamlit Logs
Streamlit app sáº½ hiá»ƒn thá»‹ status trong sidebar vÃ  main interface.

## ğŸ¯ Tips sá»­ dá»¥ng

1. **Láº§n Ä‘áº§u setup**: Cháº¡y vá»›i Ã­t files Ä‘á»ƒ test (set `NUM_MARKDOWN_FILES=5`)
2. **Production**: Sá»­ dá»¥ng cáº¥u hÃ¬nh máº·c Ä‘á»‹nh Ä‘Ã£ tá»‘i Æ°u
3. **Performance**: Monitor Neo4j memory usage
4. **Queries**: Báº¯t Ä‘áº§u vá»›i quick queries trÆ°á»›c khi dÃ¹ng custom queries
5. **Embedding**: Model sáº½ tá»± download láº§n Ä‘áº§u (~133MB)

## ğŸ”¬ Technical Details

### Models Used:
- **LLM**: GPT-4o-mini (128K context, cost-effective)
- **Embedding**: BAAI/bge-small-en-v1.5 (768-dim vectors)
- **Graph DB**: Neo4j (property graph)

### Processing Pipeline:
1. **Document Processing**: HTML â†’ Markdown â†’ Chunks
2. **Knowledge Extraction**: LLM â†’ Entities + Relations
3. **Graph Storage**: Neo4j â†’ Triplets + Communities
4. **Query Processing**: Embedding â†’ Similarity â†’ Context â†’ LLM

### Performance Optimizations:
- Configurable chunk size (default 500 tokens, can be increased)
- Batch processing for efficiency
- No node limits for complete indexing
- Optimized prompts for better extraction
- Potential for larger chunks with GPT-4o-mini's 128K context

## ğŸ†˜ Support

Náº¿u gáº·p váº¥n Ä‘á»:
1. Kiá»ƒm tra logs trong terminal
2. Kiá»ƒm tra Neo4j browser táº¡i `http://localhost:7474`
3. Kiá»ƒm tra Streamlit logs
4. Restart Neo4j service náº¿u cáº§n
5. Kiá»ƒm tra disk space cho embedding model

---

**Happy GraphRAG-ing! ğŸ•¸ï¸**


